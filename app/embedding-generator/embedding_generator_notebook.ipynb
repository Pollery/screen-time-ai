{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ea6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "from fastai.vision.all import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path to the directory containing actor images\n",
    "IMAGES_FOLDER = (\n",
    "    Path(__file__).resolve().parent.parent / \"tmdb-api\" / \"images_train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5af3ec",
   "metadata": {},
   "source": [
    "# 1. Define Utility Functions\n",
    "Define small, reusable utility functions that perform specific, isolated tasks. These functions should be independent and easy to test on their own.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da21f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fastai_embeddings(image_folder: str):\n",
    "    \"\"\"\n",
    "    Generates face embeddings for all images in a given folder using a pre-trained FastAI model.\n",
    "\n",
    "    This function loads a pre-trained ResNet34 model, removes its classification head,\n",
    "    and uses the remaining 'body' to extract a high-dimensional feature vector (embedding)\n",
    "    for each face image.\n",
    "\n",
    "    Args:\n",
    "        image_folder (str): The path to the folder with face images.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - embeddings (torch.Tensor): A tensor of all generated face embeddings.\n",
    "            - actor_names (list): A list of corresponding actor names.\n",
    "    \"\"\"\n",
    "    embeddings_list = []\n",
    "    actor_names = []\n",
    "\n",
    "    try:\n",
    "        # Create the model's body directly, which is the feature-extraction part.\n",
    "        # We use 'create_body' to load the pre-trained weights without the final\n",
    "        # classification layer.\n",
    "        model = create_body(resnet34, pretrained=True)\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading the pre-trained model: {e}\")\n",
    "        print(\"Please check your internet connection and try again.\")\n",
    "        return None, None\n",
    "\n",
    "    # Ensure the images folder exists\n",
    "    image_path = Path(image_folder)\n",
    "    if not image_path.exists():\n",
    "        print(f\"Error: The folder '{image_folder}' does not exist.\")\n",
    "        return None, None\n",
    "\n",
    "    # Get a list of all image files in the folder\n",
    "    image_files = get_image_files(image_path)\n",
    "    if not image_files:\n",
    "        print(\"No image files found in the specified folder.\")\n",
    "        return None, None\n",
    "\n",
    "    print(f\"Found {len(image_files)} images. Generating embeddings...\")\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for faster inference\n",
    "        for img_path in tqdm(image_files, desc=\"Processing images\"):\n",
    "            try:\n",
    "                # Load and preprocess the image\n",
    "                img = PILImage.create(img_path)\n",
    "                # Resize to a standard size for the model\n",
    "                img_tensor = img.resize((224, 224)).to_tensor().unsqueeze(0)\n",
    "\n",
    "                # Pass the image through the model to get the embedding\n",
    "                embedding = model(img_tensor).squeeze()\n",
    "                embeddings_list.append(embedding)\n",
    "\n",
    "                # Extract the actor's name from the file name\n",
    "                actor_name = img_path.stem.replace(\"_\", \" \")\n",
    "                actor_names.append(actor_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "    # Stack all embeddings into a single tensor for efficient storage and use\n",
    "    if embeddings_list:\n",
    "        embeddings_tensor = torch.stack(embeddings_list)\n",
    "        return embeddings_tensor, actor_names\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6cbc3c",
   "metadata": {},
   "source": [
    "# 2. Implement Core Logic Components\n",
    "Break down the main problem into smaller, manageable core logic components, each implemented as a separate function. These functions should ideally take inputs and return outputs without side effects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2011b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(\n",
    "    embeddings_tensor, actor_names, output_file=\"fastai_embeddings.pth\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Saves the embeddings and corresponding names to a PyTorch file (.pth).\n",
    "\n",
    "    This is a highly efficient way to store numerical data, much faster than\n",
    "    a text-based format like JSON, and it can be easily loaded back into\n",
    "    a PyTorch environment.\n",
    "\n",
    "    Args:\n",
    "        embeddings_tensor (torch.Tensor): The tensor containing all embeddings.\n",
    "        actor_names (list): The list of actor names.\n",
    "        output_file (str): The name of the output file.\n",
    "    \"\"\"\n",
    "    torch.save(\n",
    "        {\"embeddings\": embeddings_tensor, \"names\": actor_names}, output_file\n",
    "    )\n",
    "    print(f\"\\nEmbeddings and names saved successfully to '{output_file}'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ce5ba",
   "metadata": {},
   "source": [
    "# 3. Demonstrate Component Usage and Testing\n",
    "Show how to call and test each individual function or component with various inputs. Include examples of expected outputs and potential edge cases to verify correctness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677b8421",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, names = generate_fastai_embeddings(IMAGES_FOLDER)\n",
    "if embeddings is not None:\n",
    "    save_embeddings(embeddings, names)\n",
    "    # You can now load this file later for tasks like face recognition or clustering\n",
    "    # loaded_data = torch.load('fastai_embeddings.pth')\n",
    "    # loaded_embeddings = loaded_data['embeddings']\n",
    "    # loaded_names = loaded_data['names']\n",
    "    # print(f\"\\nLoaded {len(loaded_embeddings)} embeddings.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
